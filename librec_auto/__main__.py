import argparse
from librec_auto.core.cmd.eval_cmd import EvalCmd
from librec_auto.core.config_cmd import ConfigCmd
from datetime import datetime
from pathlib import Path
from librec_auto.core import read_config_file
from librec_auto.core.util import Files, create_study_output, BBO, create_log_name, \
    purge_old_logs, InvalidConfiguration, InvalidCommand, UnsupportedFeatureException, \
    LibRecAutoException
from librec_auto.core.cmd import Cmd, SetupCmd, SequenceCmd, PurgeCmd, LibrecCmd, PostCmd, \
                                 RerankCmd, StatusCmd, ParallelCmd, CheckCmd, CleanupCmd, AlgCmd
import logging
from librec_auto.core.util.utils import move_log_file
from librec_auto.core.util.xml_utils import single_xpath
from compile import compile_commands
import librec_auto
import os


def read_args():
    '''
    Parse command line arguments.
    :return:
    '''
    parser = argparse.ArgumentParser(
        description=
        'The librec-auto tool for running recommender systems experiments.',
        epilog=
        'For documentation, refer to: https://librec-auto.readthedocs.io/en/latest/'
    )

    parser.add_argument('action',
                        choices=[
                            'run', 'split', 'eval', 'rerank', 'post', 'purge',
                            'status', 'describe', 'check', 'show'
                        ])

    parser.add_argument("-t", "--target", help="Path to experiment directory")

    # Optional with arguments
    parser.add_argument("-c",
                        "--conf",
                        help="Use the specified configuration file")

    # Flags
    parser.add_argument(
        "-dr",
        "--dry_run",
        help="Show sequence of command execution but do not execute commands",
        action="store_true")

    parser.add_argument("-q",
                        "--quiet",
                        help="Skip confirmation when purging",
                        action="store_true")

    parser.add_argument(
        "-np",
        "--no_parallel",
        help=
        "Ignore thread-count directive and run all operations sequentially",
        action="store_true")

    parser.add_argument(
        "-p",
        "--purge",
        help="Purge results of step given in <option> and all subsequent steps",
        choices=['all', 'split', 'results', 'rerank', 'post'],
        default='all')

    parser.add_argument(
        "-dev",
        "--dev",
        help="Help with documentation, code formatting, and Docker",
        action="store_true")

    parser.add_argument(
        "-k",
        "--key_password",
        help="Password for the API keys used by post-processing scripts")

    parser.add_argument(
        "-nc",
        "--no_check",
        help="Don't run the check command",
        action="store_true")

    parser.add_argument(
        "-nj",
        "--no_java_check",
        help="Don't run the java check",
        action="store_true")

    input_args = parser.parse_args()
    error_check(vars(input_args))
    return vars(input_args)

def error_check(input_arguments: dict):
    if input_arguments['target'] == None:
        raise InvalidCommand("Missing instruction", "Target (-t) argument missing from command line instruction\n"\
            "To use current directory, use \"-t .\", or for a specific directory use \"-t <directory-name>\"")

def load_config(args: dict) -> ConfigCmd:

    config_file = Files.DEFAULT_CONFIG_FILENAME

    if args['conf']:  # User requested a different configuration file from the default
        config_file = args['conf']

    target = ""
    if (args['target'] != None):
        target = args['target']
    
    log_file = args['log_name']

    # create a path: 
    
    return read_config_file(config_file, target, log_file)


DESCRIBE_TEXT = 'Librec-auto automates recommender systems experimentation using the LibRec Java library.\n' +\
    '\tA librec-auto experiment consist of five steps governed by the specifications in the configuration file:\n' +\
    '\t- split: Create training / test splits from a data set. (LibRec)\n' +\
    '\t- exp: Run an experiment generating recommendations for a test set (LibRec)\n' +\
    '\t- rerank (optional): Re-rank the results of the experiment (script)\n' +\
    '\t- eval: Evaluate the results of a recommendation experiment (LibRec)\n' +\
    '\t- post (optional): Perform post-processing computations (script)\n' + \
    'Steps labeled LibRec are performed by the LibRec library using configuration properties generated by librec-auto.\n' +\
    'Steps labeled script are performed by experimenter-defined scripts.\n' + \
    'Run librec_auto describe <step> for additional information about each option.'

DESCRIBE_DICT = {
    'run':
    'Run a complete librec-auto experiment. Re-uses cached results if any. \
May result in no action if all computations are up-to-date and no purge option is specified.',
    'split': 'Run the training / test split only',
    'exp': 'Run the experiment, re-ranking, evaluation, and post-processing',
    'rerank': 'Run the re-ranking, evaluation and post-processing',
    'eval': 'Run the evaluation and post-processing',
    'post': 'Run post-processing steps',
    'purge':
    'Purge cached computations. Uses -p flag to determine what to purge',
    'status': 'Print out the status of the experiments',
    'show': 'Show the steps compiled from the configuration file.'
}

def print_description(args: dict) -> None:
    act = args['target']
    if act in DESCRIBE_DICT:
        print(f'core {act} <target>: {DESCRIBE_DICT[act]}')
    else:
        print(DESCRIBE_TEXT)


# TODO: Need to rewrite as "build_exec_commands" where the action incorporates both execution
# and reranking. Remember that the re-ranker only requires one run of the prediction algorithm for any
# variation its own parameters.

# -------------------------------------

if __name__ == '__main__':
    
    args = read_args()
    compile = compile_commands()
    
    if args['dev']:
        log_name = create_log_name('LibRec-Auto_log{}.log')
        args['log_name'] = log_name
        librec_auto_log = str(Path(args['target']) / args['log_name'])
        logging.basicConfig(filename=librec_auto_log,filemode='w',level=logging.DEBUG)
    else:
        purge_old_logs(args['target'] + "/*")
        log_name = create_log_name('LibRec-Auto_log{}.log')
        args['log_name'] = log_name
        librec_auto_log = str(Path(args['target']) / args['log_name'])
        logging.basicConfig(filename=librec_auto_log,filemode='w',level=logging.WARNING)



    jar_path = Path(librec_auto.__file__).parent / "jar" / "auto.jar"
    if not jar_path.is_file():
        print("Error: LibRec JAR file is missing.")

    else:
        if args['action'] == 'describe':
            print_description(args)
        elif args['action'] == 'check':
            config = load_config(args)
            #config.set_python_only(needs_librec(config))
            move_log_file(config)
            if config.is_valid():
                try:
                    command = compile.setup_commands(args, config)
                    
                except LibRecAutoException:
                    print("Exception caught, check output.xml file.")
                    logging.shutdown()
                    clean = CleanupCmd()
                    clean.execute(config)
                    exit(-1)


                
                if args['dry_run']:
                    command.dry_run(config)
                else:
                    try: 
                        command.execute(config)
                    except LibRecAutoException:
                        print("Exception caught, check output.xml file.")
                        logging.shutdown()
                        clean = CleanupCmd()
                        clean.execute(config)
                        exit(-1)
        else:
            config = load_config(args)
            
            if config.is_valid():
                try:
                    command = compile.setup_commands(args, config)
                except LibRecAutoException:
                    print("Exception caught, check output.xml file.")
                    logging.shutdown()
                    clean = CleanupCmd()
                    clean.execute(config)
                    exit(-1)

                if len(config._xml_input.xpath('/librec-auto/alg//*/lower')) >0 and \
                        (args['action'] == 'run' or args['action'] == 'dry_run'):
                    if args['action'] == 'run':
                        args['action'] = 'bbo'
                    print('Running BBO. Recreating Config.')
                    config = load_config(args)
                    command = compile.setup_commands(args, config)

                if isinstance(command, Cmd):
                    if args['action'] == 'show':
                        command.show()
                    elif args['dry_run']:
                        command.dry_run(config)
                    else:
                        try: 
                            command.execute(config)
                        except LibRecAutoException:
                            print("Exception caught, check output.xml file.")
                            logging.shutdown()
                            clean = CleanupCmd()
                            clean.execute(config)
                            exit(-1)
                            


                elif isinstance(command, list):
                    if args['action'] == 'show':
                        for cmd in command:
                            cmd.show()
                    else:
                        vconf = config._var_coll.var_confs

                        num_of_vars = len([0 for var in vconf[0].vars])

                        range_val_store = [[i.val for i in j.vars if i.type == 'librec'] for j in vconf]

                        range_val_store = [[float(array[i]) for array in range_val_store] for i in range(len(range_val_store[0]))]

                        range_val_store = [[min(array), max(array)] for array in range_val_store]

                        check_rerank = len([elem.text for elem in config._xml_input.xpath('/librec-auto/rerank/*//lower')])

                        if check_rerank > 0:
                            raise InvalidConfiguration("Optimization", "Optimization is not currently supported with reranking")

                        # exponent_expected = num_of_vars
                        #
                        # for tup in range_val_store:
                        #     if tup[0] == tup[1]:
                        #         exponent_expected -= 1

                        # if 2**exponent_expected == config.get_sub_exp_count():
                        range_list = [(range_val_store[i][0],range_val_store[i][1]) for i in range(len(range_val_store))]
                        value_elems = [elem.text for elem in config._xml_input.xpath('/librec-auto/optimize/iterations')]

                        continue_rerank = False

                        if isinstance(command[-2], RerankCmd):

                            final_commands = command[-2:]

                            command = command[:int(value_elems[0])+2]

                            continue_rerank = True

                            command = command + final_commands

                        bbo = BBO.BBO(range_list, len(range_val_store), command[3:], config)
                        file_path = bbo.run_purge(command[0])

                        metric = [elem.text for elem in config._xml_input.xpath('/librec-auto/optimize/metric')][0]

                        if metric in bbo.metric_map:
                            bbo.set_optimization_direction(metric)
                        else:
                            bbo.set_optimization_direction(config._xml_input.xpath('/librec-auto/metric/@optimize')[0])

                        # Setup Command
                        command[1].execute(config, startflag = 1, exp_no = int(value_elems[0]))
                        # Split Command
                        command[2].execute(config)

                        bbo.file_path = file_path

                        bbo.run(int(value_elems[0]))

                        # print("continue_rerank", config.has_rerank())
                        # if config.has_rerank():
                        #     command[-3].execute(config)
                        #     # command[-2].execute(config)
                        #     command[-1].execute(config)
                        # else:
                        cleanup = command[-1]
                        cleanup.execute(config)
                        create_study_output(config)



                 #   else:
                 #       print("Each range must have only two values!")
                 #       print("Expected", exponent_expected, "values, got", config.get_sub_exp_count())
                     
                else:
                    logging.error("Command instantiation failed.")
            else:
                logging.error("Configuration loading failed.")
        os.remove(librec_auto_log)
    

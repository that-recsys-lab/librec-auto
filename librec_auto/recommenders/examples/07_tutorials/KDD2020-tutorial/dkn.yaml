data:
  doc_size: 15  # Each feature length should be fixed at doc_size, if the number of words in document is more than doc_size, you should truncate the document to doc_size words, and if the number of words in document is less than doc_size, you should padding 0. 
  his_size: 20  # Max number of user click history, we will automatically keep the last his_size number of user click history, if users' click history is more than his_size, and we will automatically padding 0 if less than his_size.
  word_size: 194755  # word vocabulary size
  entity_size: 57267 # entity vocabulary size
  data_format: dkn
  
info:
  metrics:
  - auc
  pairwise_metrics:
  - group_auc
  - mean_mrr
  - ndcg@2;4;6
  show_step: 10000  # print loss every show_step batches
  
model:
  method : classification
  activation:
  - sigmoid
  attention_activation: relu
  attention_dropout: 0.0
  attention_layer_sizes: 32
  dim: 32  # word embedding dim
  use_entity: true # use entity embedding
  use_context: true # use context embedding
 
  entity_dim: 32 # entity embedding dim
  entity_embedding_method: TransE
  transform: true # add a transform layer for entity and context embeddings
 
  dropout:
  - 0.0
  filter_sizes: # window size of kcnn filters
  - 1
  - 2
  - 3
  layer_sizes:  # layer size for final prediction score layer
  - 300
  # model_type: DKN_without_context
  model_type: dkn
  num_filters: 50   # number of filter for each filter_size in kcnn part
  infer_model_name : epoch_2

train:
  batch_size: 100
  embed_l1: 0.000
  embed_l2: 0.000001
  epochs: 50
  init_method: uniform
  init_value: 0.01
  layer_l1: 0.000
  layer_l2: 0.000001
  learning_rate: 0.00005
  loss: log_loss
  optimizer: adam
  save_model: True
  save_epoch : 1 # save model every save_epoch epochs
  enable_BN : False
  is_clip_norm: False
  max_grad_norm: 0.5
